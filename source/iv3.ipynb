{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model_name', type=str, default='InceptionV3')\n",
    "parser.add_argument('--weights', type=str, default='radimagenet')\n",
    "parser.add_argument('--n_layers', type=int, default=4)\n",
    "parser.add_argument('--n_neurons', type=int, default=256)\n",
    "parser.add_argument('--n_dropout', type=float, default=0.0)\n",
    "parser.add_argument('--lr_1', type=float, default=3e-4)\n",
    "parser.add_argument('--lr_2', type=float, default=3e-6)\n",
    "parser.add_argument('--image_size', type=int, default=512, required=False)\n",
    "parser.add_argument('--batch_size', type=int, default=16, required=False)\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "model_name = args.model_name\n",
    "weights = args.weights\n",
    "n_layers = args.n_layers\n",
    "n_neurons = args.n_neurons\n",
    "n_dropout = args.n_dropout\n",
    "lr_1 = args.lr_1\n",
    "lr_2 = args.lr_2\n",
    "img_size = args.image_size\n",
    "batch_size = args.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 14:07:03.084010: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-16 14:07:04.184509: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-16 14:07:04.184595: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-16 14:07:04.184604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You do not have pycocotools installed, so KerasCV pycoco metrics are not available. Please run `pip install pycocotools`.\n",
      "You do not have pyococotools installed, so the `PyCOCOCallback` API is not available.\n",
      "You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.\n",
      "Found 492 files belonging to 2 classes.\n",
      "Found 165 files belonging to 2 classes.\n",
      "Found 164 files belonging to 2 classes.\n",
      "WARNING:tensorflow:From /home/kchen/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 14:07:06.905112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-16 14:07:08.570136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18266 MB memory:  -> device: 0, name: NVIDIA RTX A4500, pci bus id: 0000:81:00.0, compute capability: 8.6\n",
      "2023-02-16 14:07:08.570809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9262 MB memory:  -> device: 1, name: NVIDIA TITAN V, pci bus id: 0000:02:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, recall_score\n",
    "from tensorflow.keras.applications import InceptionResNetV2, ResNet50, InceptionV3, DenseNet121, Xception\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import keras_cv\n",
    "\n",
    "\n",
    "# %%\n",
    "train_dir = '../data/split_1/train'\n",
    "val_dir = '../data/split_1/val'\n",
    "test_dir = '../data/split_1/test'\n",
    "\n",
    "\n",
    "# %%\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(train_dir, label_mode='binary', seed=0, image_size=(img_size, img_size), batch_size=batch_size, color_mode='rgb', crop_to_aspect_ratio=False)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(val_dir, label_mode='binary', seed=0, image_size=(img_size, img_size), batch_size=batch_size, color_mode='rgb', crop_to_aspect_ratio=False)\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir, label_mode='binary', seed=0, image_size=(img_size, img_size), batch_size=1, color_mode='rgb', crop_to_aspect_ratio=False)\n",
    "\n",
    "\n",
    "# %%\n",
    "#Apply data augmentation\n",
    "preprocessing_model = tf.keras.Sequential()\n",
    "preprocessing_model.add(\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(40))\n",
    "preprocessing_model.add(\n",
    "    tf.keras.layers.experimental.preprocessing.RandomTranslation(0.2, 0.2))\n",
    "preprocessing_model.add(\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2, 0.2))\n",
    "preprocessing_model.add(\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\"))\n",
    "preprocessing_model.add(\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"vertical\"))\n",
    "#add cutmix augmentation\n",
    "# preprocessing_model.add(keras_cv.layers.CutMix(1.0))\n",
    "#add random cutout augmentation\n",
    "# preprocessing_model.add(keras_cv.layers.RandomCutout(0.5, 0.5))\n",
    "\n",
    "\n",
    "# %%\n",
    "train_ds = train_ds.map(lambda images, labels:\n",
    "                        (preprocessing_model(images), labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'InceptionResNetV2':\n",
    "    preprocess_fx = tf.keras.applications.inception_resnet_v2.preprocess_input\n",
    "    model_dir = \"../RadImageNet/models/RadImageNet-IRV2_notop.h5\"\n",
    "    if weights == 'imagenet':\n",
    "        base_model = InceptionResNetV2(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet', pooling='avg')\n",
    "    elif weights == 'radimagenet':\n",
    "        base_model = InceptionResNetV2(input_shape=(img_size, img_size, 3), include_top=False, weights=model_dir, pooling='avg')\n",
    "elif model_name == 'ResNet50':\n",
    "    preprocess_fx = tf.keras.applications.resnet50.preprocess_input\n",
    "    model_dir = \"../RadImageNet/models/RadImageNet-ResNet50_notop.h5\"\n",
    "    if weights == 'imagenet':\n",
    "        base_model = ResNet50(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet', pooling='avg')\n",
    "    elif weights == 'radimagenet':\n",
    "        base_model = ResNet50(input_shape=(img_size, img_size, 3), include_top=False, weights=model_dir, pooling='avg')\n",
    "elif model_name == 'InceptionV3':\n",
    "    preprocess_fx = tf.keras.applications.inception_v3.preprocess_input\n",
    "    model_dir = \"../RadImageNet/models/RadImageNet-InceptionV3_notop.h5\"\n",
    "    if weights == 'imagenet':\n",
    "        base_model = InceptionV3(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet', pooling='avg')\n",
    "    elif weights == 'radimagenet':\n",
    "        base_model = InceptionV3(input_shape=(img_size, img_size, 3), include_top=False, weights=model_dir, pooling='avg')\n",
    "elif model_name == 'DenseNet121':\n",
    "    preprocess_fx = tf.keras.applications.densenet.preprocess_input\n",
    "    model_dir = \"../RadImageNet/models/RadImageNet-DenseNet121_notop.h5\"\n",
    "    if weights == 'imagenet':\n",
    "        base_model = DenseNet121(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet', pooling='avg')\n",
    "    elif weights == 'radimagenet':\n",
    "        base_model = DenseNet121(input_shape=(img_size, img_size, 3), include_top=False, weights=model_dir, pooling='avg')\n",
    "elif model_name == 'Xception':\n",
    "    preprocess_fx = tf.keras.applications.xception.preprocess_input\n",
    "    if weights == 'imagenet':\n",
    "        base_model = tf.keras.applications.Xception(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet', pooling='avg')\n",
    "elif model_name == 'BiT':\n",
    "    base_model = hub.KerasLayer(\"https://tfhub.dev/google/bit/m-r50x1/1\", trainable=False)\n",
    "    preprocess_fx = tf.keras.applications.resnet50.preprocess_input\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "y = preprocess_fx(inputs)\n",
    "y = base_model(y, training=False)\n",
    "for i in range(n_layers):\n",
    "    y = keras.layers.Dense(n_neurons, activation='relu')(y)\n",
    "    y = keras.layers.Dropout(n_dropout)(y)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(y)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# %%\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=50, min_delta=1e-10, restore_best_weights=True)\n",
    "\n",
    "# %%\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr_1), \n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()],\n",
    ")\n",
    "\n",
    "epochs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 14:07:38.403212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8800\n",
      "2023-02-16 14:07:40.437870: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:40.440511: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2023-02-16 14:07:40.440527: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas\n",
      "2023-02-16 14:07:40.440621: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-02-16 14:07:42.371763: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-02-16 14:07:42.378273: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fafec7b95b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-16 14:07:42.378326: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A4500, Compute Capability 8.6\n",
      "2023-02-16 14:07:42.378340: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA TITAN V, Compute Capability 7.0\n",
      "2023-02-16 14:07:42.388037: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-16 14:07:42.501416: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:42.505546: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-02-16 14:07:42.622700: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:42.807850: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:43.445015: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:43.542330: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:44.278524: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:45.533201: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:45.636865: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:45.728958: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:45.868268: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:51.619976: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:55.494941: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:56.780772: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:56.960406: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:57.383384: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:58.418539: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:07:58.635020: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:08:00.369758: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2023-02-16 14:08:02.114174: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/31 [..............................] - ETA: 22:11 - loss: 0.6974 - binary_accuracy: 0.3125 - auc: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 14:08:03.050426: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 71s 896ms/step - loss: 0.6950 - binary_accuracy: 0.5142 - auc: 0.4972 - val_loss: 0.6909 - val_binary_accuracy: 0.5273 - val_auc: 0.5811\n",
      "Epoch 2/1000\n",
      "31/31 [==============================] - 23s 731ms/step - loss: 0.6932 - binary_accuracy: 0.5000 - auc: 0.4886 - val_loss: 0.6914 - val_binary_accuracy: 0.5273 - val_auc: 0.5339\n",
      "Epoch 3/1000\n",
      "31/31 [==============================] - 23s 723ms/step - loss: 0.6861 - binary_accuracy: 0.5467 - auc: 0.5835 - val_loss: 0.7214 - val_binary_accuracy: 0.5273 - val_auc: 0.5681\n",
      "Epoch 4/1000\n",
      "31/31 [==============================] - 23s 729ms/step - loss: 0.6960 - binary_accuracy: 0.5285 - auc: 0.5257 - val_loss: 0.6918 - val_binary_accuracy: 0.5576 - val_auc: 0.5575\n",
      "Epoch 5/1000\n",
      "31/31 [==============================] - 23s 723ms/step - loss: 0.6859 - binary_accuracy: 0.5650 - auc: 0.5784 - val_loss: 0.6919 - val_binary_accuracy: 0.5515 - val_auc: 0.5680\n",
      "Epoch 6/1000\n",
      "31/31 [==============================] - 24s 743ms/step - loss: 0.6840 - binary_accuracy: 0.5650 - auc: 0.5741 - val_loss: 0.6826 - val_binary_accuracy: 0.5455 - val_auc: 0.6354\n",
      "Epoch 7/1000\n",
      "31/31 [==============================] - 23s 729ms/step - loss: 0.6786 - binary_accuracy: 0.5772 - auc: 0.5988 - val_loss: 0.6751 - val_binary_accuracy: 0.5636 - val_auc: 0.6256\n",
      "Epoch 8/1000\n",
      "31/31 [==============================] - 23s 711ms/step - loss: 0.6643 - binary_accuracy: 0.5935 - auc: 0.6304 - val_loss: 0.7135 - val_binary_accuracy: 0.5394 - val_auc: 0.6009\n",
      "Epoch 9/1000\n",
      "31/31 [==============================] - 23s 734ms/step - loss: 0.6809 - binary_accuracy: 0.5915 - auc: 0.6141 - val_loss: 0.6820 - val_binary_accuracy: 0.5212 - val_auc: 0.6401\n",
      "Epoch 10/1000\n",
      "31/31 [==============================] - 23s 727ms/step - loss: 0.6860 - binary_accuracy: 0.5467 - auc: 0.5877 - val_loss: 0.6794 - val_binary_accuracy: 0.5394 - val_auc: 0.6628\n",
      "Epoch 11/1000\n",
      "31/31 [==============================] - 23s 719ms/step - loss: 0.6758 - binary_accuracy: 0.5752 - auc: 0.6312 - val_loss: 0.6760 - val_binary_accuracy: 0.5576 - val_auc: 0.6059\n",
      "Epoch 12/1000\n",
      "31/31 [==============================] - 23s 734ms/step - loss: 0.6763 - binary_accuracy: 0.5589 - auc: 0.6052 - val_loss: 0.6769 - val_binary_accuracy: 0.5333 - val_auc: 0.6237\n",
      "Epoch 13/1000\n",
      "31/31 [==============================] - 23s 736ms/step - loss: 0.6521 - binary_accuracy: 0.6321 - auc: 0.6676 - val_loss: 0.6839 - val_binary_accuracy: 0.5636 - val_auc: 0.6410\n",
      "Epoch 14/1000\n",
      "31/31 [==============================] - 23s 732ms/step - loss: 0.6581 - binary_accuracy: 0.6016 - auc: 0.6436 - val_loss: 0.7001 - val_binary_accuracy: 0.6364 - val_auc: 0.6791\n",
      "Epoch 15/1000\n",
      "31/31 [==============================] - 23s 726ms/step - loss: 0.6577 - binary_accuracy: 0.6057 - auc: 0.6488 - val_loss: 0.6801 - val_binary_accuracy: 0.5697 - val_auc: 0.6132\n",
      "Epoch 16/1000\n",
      "31/31 [==============================] - 23s 724ms/step - loss: 0.6555 - binary_accuracy: 0.6280 - auc: 0.6575 - val_loss: 0.6862 - val_binary_accuracy: 0.5333 - val_auc: 0.6534\n",
      "Epoch 17/1000\n",
      "31/31 [==============================] - 23s 719ms/step - loss: 0.6359 - binary_accuracy: 0.6402 - auc: 0.6803 - val_loss: 0.6785 - val_binary_accuracy: 0.5939 - val_auc: 0.6757\n",
      "Epoch 18/1000\n",
      "31/31 [==============================] - 23s 723ms/step - loss: 0.6419 - binary_accuracy: 0.6240 - auc: 0.6823 - val_loss: 0.6900 - val_binary_accuracy: 0.5394 - val_auc: 0.6821\n",
      "Epoch 19/1000\n",
      "31/31 [==============================] - 23s 733ms/step - loss: 0.6441 - binary_accuracy: 0.6159 - auc: 0.6812 - val_loss: 0.6866 - val_binary_accuracy: 0.5636 - val_auc: 0.6549\n",
      "Epoch 20/1000\n",
      "31/31 [==============================] - 23s 726ms/step - loss: 0.6449 - binary_accuracy: 0.6138 - auc: 0.6735 - val_loss: 0.6934 - val_binary_accuracy: 0.6000 - val_auc: 0.6468\n",
      "Epoch 21/1000\n",
      "31/31 [==============================] - 23s 725ms/step - loss: 0.6282 - binary_accuracy: 0.6423 - auc: 0.7099 - val_loss: 0.7115 - val_binary_accuracy: 0.5939 - val_auc: 0.6424\n",
      "Epoch 22/1000\n",
      "31/31 [==============================] - 23s 716ms/step - loss: 0.6440 - binary_accuracy: 0.6280 - auc: 0.6794 - val_loss: 0.6809 - val_binary_accuracy: 0.6061 - val_auc: 0.6285\n",
      "Epoch 23/1000\n",
      "31/31 [==============================] - 23s 737ms/step - loss: 0.6323 - binary_accuracy: 0.6524 - auc: 0.6983 - val_loss: 0.7198 - val_binary_accuracy: 0.5394 - val_auc: 0.6183\n",
      "Epoch 24/1000\n",
      "31/31 [==============================] - 23s 728ms/step - loss: 0.6497 - binary_accuracy: 0.6280 - auc: 0.6634 - val_loss: 0.7167 - val_binary_accuracy: 0.5212 - val_auc: 0.5749\n",
      "Epoch 25/1000\n",
      "31/31 [==============================] - 23s 733ms/step - loss: 0.6286 - binary_accuracy: 0.6463 - auc: 0.7057 - val_loss: 0.7222 - val_binary_accuracy: 0.6061 - val_auc: 0.6732\n",
      "Epoch 26/1000\n",
      "31/31 [==============================] - 23s 720ms/step - loss: 0.6205 - binary_accuracy: 0.6504 - auc: 0.7074 - val_loss: 0.6892 - val_binary_accuracy: 0.5697 - val_auc: 0.5823\n",
      "Epoch 27/1000\n",
      "31/31 [==============================] - 23s 732ms/step - loss: 0.6052 - binary_accuracy: 0.6707 - auc: 0.7369 - val_loss: 0.7165 - val_binary_accuracy: 0.6000 - val_auc: 0.6537\n",
      "Epoch 28/1000\n",
      "31/31 [==============================] - 23s 734ms/step - loss: 0.5973 - binary_accuracy: 0.6768 - auc: 0.7388 - val_loss: 0.7096 - val_binary_accuracy: 0.5636 - val_auc: 0.5819\n",
      "Epoch 29/1000\n",
      "31/31 [==============================] - 22s 704ms/step - loss: 0.6167 - binary_accuracy: 0.6626 - auc: 0.7209 - val_loss: 0.7250 - val_binary_accuracy: 0.6424 - val_auc: 0.6695\n",
      "Epoch 30/1000\n",
      "31/31 [==============================] - 22s 701ms/step - loss: 0.6229 - binary_accuracy: 0.6423 - auc: 0.6959 - val_loss: 0.7307 - val_binary_accuracy: 0.5576 - val_auc: 0.6362\n",
      "Epoch 31/1000\n",
      "31/31 [==============================] - 23s 726ms/step - loss: 0.5926 - binary_accuracy: 0.6829 - auc: 0.7464 - val_loss: 0.7975 - val_binary_accuracy: 0.5636 - val_auc: 0.6424\n",
      "Epoch 32/1000\n",
      "31/31 [==============================] - 23s 717ms/step - loss: 0.6094 - binary_accuracy: 0.6667 - auc: 0.7209 - val_loss: 0.7127 - val_binary_accuracy: 0.5515 - val_auc: 0.6412\n",
      "Epoch 33/1000\n",
      "31/31 [==============================] - 22s 708ms/step - loss: 0.5926 - binary_accuracy: 0.6748 - auc: 0.7444 - val_loss: 0.7177 - val_binary_accuracy: 0.6000 - val_auc: 0.6334\n",
      "Epoch 34/1000\n",
      "31/31 [==============================] - 23s 722ms/step - loss: 0.5874 - binary_accuracy: 0.6850 - auc: 0.7566 - val_loss: 0.7806 - val_binary_accuracy: 0.6121 - val_auc: 0.6412\n",
      "Epoch 35/1000\n",
      "31/31 [==============================] - 23s 733ms/step - loss: 0.5787 - binary_accuracy: 0.6768 - auc: 0.7559 - val_loss: 0.7230 - val_binary_accuracy: 0.5939 - val_auc: 0.6412\n",
      "Epoch 36/1000\n",
      "31/31 [==============================] - 22s 703ms/step - loss: 0.5811 - binary_accuracy: 0.6870 - auc: 0.7452 - val_loss: 0.7593 - val_binary_accuracy: 0.6121 - val_auc: 0.6270\n",
      "Epoch 37/1000\n",
      "31/31 [==============================] - 23s 729ms/step - loss: 0.5962 - binary_accuracy: 0.6890 - auc: 0.7461 - val_loss: 0.7691 - val_binary_accuracy: 0.5273 - val_auc: 0.5532\n",
      "Epoch 38/1000\n",
      "31/31 [==============================] - 23s 721ms/step - loss: 0.5892 - binary_accuracy: 0.6890 - auc: 0.7461 - val_loss: 0.7347 - val_binary_accuracy: 0.6000 - val_auc: 0.5996\n",
      "Epoch 39/1000\n",
      "31/31 [==============================] - 23s 724ms/step - loss: 0.5859 - binary_accuracy: 0.6829 - auc: 0.7429 - val_loss: 0.7082 - val_binary_accuracy: 0.5455 - val_auc: 0.5791\n",
      "Epoch 40/1000\n",
      "31/31 [==============================] - 23s 730ms/step - loss: 0.5880 - binary_accuracy: 0.7093 - auc: 0.7608 - val_loss: 0.7658 - val_binary_accuracy: 0.6061 - val_auc: 0.6222\n",
      "Epoch 41/1000\n",
      "31/31 [==============================] - 22s 711ms/step - loss: 0.5715 - binary_accuracy: 0.7033 - auc: 0.7650 - val_loss: 0.7294 - val_binary_accuracy: 0.5818 - val_auc: 0.6219\n",
      "Epoch 42/1000\n",
      "31/31 [==============================] - 23s 713ms/step - loss: 0.5561 - binary_accuracy: 0.7114 - auc: 0.7730 - val_loss: 0.7534 - val_binary_accuracy: 0.5818 - val_auc: 0.6389\n",
      "Epoch 43/1000\n",
      "31/31 [==============================] - 23s 725ms/step - loss: 0.5347 - binary_accuracy: 0.7053 - auc: 0.8026 - val_loss: 0.7840 - val_binary_accuracy: 0.5879 - val_auc: 0.6254\n",
      "Epoch 44/1000\n",
      "31/31 [==============================] - 23s 729ms/step - loss: 0.5828 - binary_accuracy: 0.6687 - auc: 0.7540 - val_loss: 0.7461 - val_binary_accuracy: 0.6182 - val_auc: 0.6572\n",
      "Epoch 45/1000\n",
      "31/31 [==============================] - 23s 718ms/step - loss: 0.5304 - binary_accuracy: 0.7134 - auc: 0.7952 - val_loss: 0.8047 - val_binary_accuracy: 0.5515 - val_auc: 0.5830\n",
      "Epoch 46/1000\n",
      "31/31 [==============================] - 23s 720ms/step - loss: 0.5771 - binary_accuracy: 0.6870 - auc: 0.7561 - val_loss: 0.6878 - val_binary_accuracy: 0.6545 - val_auc: 0.6708\n",
      "Epoch 47/1000\n",
      "31/31 [==============================] - 23s 717ms/step - loss: 0.5482 - binary_accuracy: 0.7256 - auc: 0.7962 - val_loss: 0.7581 - val_binary_accuracy: 0.6364 - val_auc: 0.6482\n",
      "Epoch 48/1000\n",
      "31/31 [==============================] - 23s 712ms/step - loss: 0.5387 - binary_accuracy: 0.7134 - auc: 0.7932 - val_loss: 0.7834 - val_binary_accuracy: 0.5697 - val_auc: 0.5757\n",
      "Epoch 49/1000\n",
      "31/31 [==============================] - 23s 727ms/step - loss: 0.5343 - binary_accuracy: 0.6972 - auc: 0.8024 - val_loss: 0.7414 - val_binary_accuracy: 0.5515 - val_auc: 0.5852\n",
      "Epoch 50/1000\n",
      "31/31 [==============================] - 23s 723ms/step - loss: 0.5247 - binary_accuracy: 0.7337 - auc: 0.8063 - val_loss: 0.8998 - val_binary_accuracy: 0.5879 - val_auc: 0.5748\n",
      "Epoch 51/1000\n",
      "31/31 [==============================] - 22s 704ms/step - loss: 0.5715 - binary_accuracy: 0.7053 - auc: 0.7663 - val_loss: 0.6784 - val_binary_accuracy: 0.6000 - val_auc: 0.6661\n",
      "Epoch 52/1000\n",
      "31/31 [==============================] - 23s 722ms/step - loss: 0.5492 - binary_accuracy: 0.7093 - auc: 0.7914 - val_loss: 0.7161 - val_binary_accuracy: 0.5818 - val_auc: 0.6177\n",
      "Epoch 53/1000\n",
      "31/31 [==============================] - 23s 713ms/step - loss: 0.5337 - binary_accuracy: 0.7154 - auc: 0.7989 - val_loss: 0.7690 - val_binary_accuracy: 0.5818 - val_auc: 0.5945\n",
      "Epoch 54/1000\n",
      "31/31 [==============================] - 22s 707ms/step - loss: 0.5059 - binary_accuracy: 0.7337 - auc: 0.8256 - val_loss: 0.8350 - val_binary_accuracy: 0.6000 - val_auc: 0.6317\n",
      "Epoch 55/1000\n",
      "31/31 [==============================] - 23s 713ms/step - loss: 0.5105 - binary_accuracy: 0.7195 - auc: 0.8186 - val_loss: 0.7850 - val_binary_accuracy: 0.6364 - val_auc: 0.6575\n",
      "Epoch 56/1000\n",
      "31/31 [==============================] - 23s 715ms/step - loss: 0.5084 - binary_accuracy: 0.7703 - auc: 0.8347 - val_loss: 0.7836 - val_binary_accuracy: 0.6182 - val_auc: 0.6449\n",
      "Epoch 57/1000\n",
      "31/31 [==============================] - 24s 749ms/step - loss: 0.5093 - binary_accuracy: 0.7378 - auc: 0.8172 - val_loss: 0.8024 - val_binary_accuracy: 0.5939 - val_auc: 0.6336\n",
      "phase 1 complete\n",
      "Epoch 1/1000\n",
      "31/31 [==============================] - 55s 744ms/step - loss: 0.6621 - binary_accuracy: 0.5894 - auc_1: 0.6649 - val_loss: 0.6752 - val_binary_accuracy: 0.5515 - val_auc_1: 0.6253\n",
      "Epoch 2/1000\n",
      "31/31 [==============================] - 23s 733ms/step - loss: 0.6610 - binary_accuracy: 0.6016 - auc_1: 0.6579 - val_loss: 0.6753 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6264\n",
      "Epoch 3/1000\n",
      "31/31 [==============================] - 23s 718ms/step - loss: 0.6627 - binary_accuracy: 0.5833 - auc_1: 0.6567 - val_loss: 0.6756 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6246\n",
      "Epoch 4/1000\n",
      "31/31 [==============================] - 23s 731ms/step - loss: 0.6604 - binary_accuracy: 0.6077 - auc_1: 0.6597 - val_loss: 0.6757 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6269\n",
      "Epoch 5/1000\n",
      "31/31 [==============================] - 23s 728ms/step - loss: 0.6576 - binary_accuracy: 0.6118 - auc_1: 0.6631 - val_loss: 0.6761 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6267\n",
      "Epoch 6/1000\n",
      "31/31 [==============================] - 23s 731ms/step - loss: 0.6576 - binary_accuracy: 0.6037 - auc_1: 0.6641 - val_loss: 0.6763 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6245\n",
      "Epoch 7/1000\n",
      "31/31 [==============================] - 23s 716ms/step - loss: 0.6580 - binary_accuracy: 0.6098 - auc_1: 0.6711 - val_loss: 0.6766 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6252\n",
      "Epoch 8/1000\n",
      "31/31 [==============================] - 23s 736ms/step - loss: 0.6572 - binary_accuracy: 0.6260 - auc_1: 0.6627 - val_loss: 0.6768 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6229\n",
      "Epoch 9/1000\n",
      "31/31 [==============================] - 23s 724ms/step - loss: 0.6524 - binary_accuracy: 0.6057 - auc_1: 0.6804 - val_loss: 0.6771 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6236\n",
      "Epoch 10/1000\n",
      "31/31 [==============================] - 23s 731ms/step - loss: 0.6538 - binary_accuracy: 0.6138 - auc_1: 0.6748 - val_loss: 0.6771 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6212\n",
      "Epoch 11/1000\n",
      "31/31 [==============================] - 23s 728ms/step - loss: 0.6514 - binary_accuracy: 0.6260 - auc_1: 0.6745 - val_loss: 0.6774 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6208\n",
      "Epoch 12/1000\n",
      "31/31 [==============================] - 23s 722ms/step - loss: 0.6557 - binary_accuracy: 0.6098 - auc_1: 0.6585 - val_loss: 0.6778 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6191\n",
      "Epoch 13/1000\n",
      "31/31 [==============================] - 23s 715ms/step - loss: 0.6506 - binary_accuracy: 0.6240 - auc_1: 0.6801 - val_loss: 0.6782 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6180\n",
      "Epoch 14/1000\n",
      "31/31 [==============================] - 23s 727ms/step - loss: 0.6524 - binary_accuracy: 0.6179 - auc_1: 0.6722 - val_loss: 0.6785 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6143\n",
      "Epoch 15/1000\n",
      "31/31 [==============================] - 23s 720ms/step - loss: 0.6538 - binary_accuracy: 0.6077 - auc_1: 0.6641 - val_loss: 0.6787 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6142\n",
      "Epoch 16/1000\n",
      "31/31 [==============================] - 23s 719ms/step - loss: 0.6489 - binary_accuracy: 0.6118 - auc_1: 0.6822 - val_loss: 0.6789 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6152\n",
      "Epoch 17/1000\n",
      "31/31 [==============================] - 23s 732ms/step - loss: 0.6451 - binary_accuracy: 0.6220 - auc_1: 0.6794 - val_loss: 0.6788 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6149\n",
      "Epoch 18/1000\n",
      "31/31 [==============================] - 23s 723ms/step - loss: 0.6560 - binary_accuracy: 0.5935 - auc_1: 0.6541 - val_loss: 0.6786 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6174\n",
      "Epoch 19/1000\n",
      "31/31 [==============================] - 23s 735ms/step - loss: 0.6485 - binary_accuracy: 0.6098 - auc_1: 0.6726 - val_loss: 0.6788 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6181\n",
      "Epoch 20/1000\n",
      "31/31 [==============================] - 23s 735ms/step - loss: 0.6520 - binary_accuracy: 0.6016 - auc_1: 0.6649 - val_loss: 0.6788 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6200\n",
      "Epoch 21/1000\n",
      "31/31 [==============================] - 23s 728ms/step - loss: 0.6480 - binary_accuracy: 0.6260 - auc_1: 0.6717 - val_loss: 0.6788 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6181\n",
      "Epoch 22/1000\n",
      "31/31 [==============================] - 23s 726ms/step - loss: 0.6490 - binary_accuracy: 0.6016 - auc_1: 0.6714 - val_loss: 0.6790 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6172\n",
      "Epoch 23/1000\n",
      "31/31 [==============================] - 23s 729ms/step - loss: 0.6458 - binary_accuracy: 0.6220 - auc_1: 0.6800 - val_loss: 0.6793 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6165\n",
      "Epoch 24/1000\n",
      "31/31 [==============================] - 23s 716ms/step - loss: 0.6445 - binary_accuracy: 0.6341 - auc_1: 0.6855 - val_loss: 0.6794 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6172\n",
      "Epoch 25/1000\n",
      "31/31 [==============================] - 23s 732ms/step - loss: 0.6497 - binary_accuracy: 0.6138 - auc_1: 0.6619 - val_loss: 0.6792 - val_binary_accuracy: 0.5212 - val_auc_1: 0.6179\n",
      "Epoch 26/1000\n",
      "31/31 [==============================] - 23s 711ms/step - loss: 0.6415 - binary_accuracy: 0.6220 - auc_1: 0.6834 - val_loss: 0.6794 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6165\n",
      "Epoch 27/1000\n",
      "31/31 [==============================] - 23s 709ms/step - loss: 0.6382 - binary_accuracy: 0.6159 - auc_1: 0.6912 - val_loss: 0.6796 - val_binary_accuracy: 0.5273 - val_auc_1: 0.6202\n",
      "Epoch 28/1000\n",
      "31/31 [==============================] - 23s 716ms/step - loss: 0.6399 - binary_accuracy: 0.6280 - auc_1: 0.6889 - val_loss: 0.6796 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6202\n",
      "Epoch 29/1000\n",
      "31/31 [==============================] - 23s 724ms/step - loss: 0.6403 - binary_accuracy: 0.6240 - auc_1: 0.6795 - val_loss: 0.6794 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6199\n",
      "Epoch 30/1000\n",
      "31/31 [==============================] - 23s 718ms/step - loss: 0.6413 - binary_accuracy: 0.6260 - auc_1: 0.6866 - val_loss: 0.6793 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6200\n",
      "Epoch 31/1000\n",
      "31/31 [==============================] - 22s 708ms/step - loss: 0.6421 - binary_accuracy: 0.6138 - auc_1: 0.6774 - val_loss: 0.6792 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6226\n",
      "Epoch 32/1000\n",
      "31/31 [==============================] - 23s 725ms/step - loss: 0.6392 - binary_accuracy: 0.6138 - auc_1: 0.6804 - val_loss: 0.6794 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6204\n",
      "Epoch 33/1000\n",
      "31/31 [==============================] - 23s 737ms/step - loss: 0.6359 - binary_accuracy: 0.6341 - auc_1: 0.6934 - val_loss: 0.6801 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6236\n",
      "Epoch 34/1000\n",
      "31/31 [==============================] - 23s 718ms/step - loss: 0.6346 - binary_accuracy: 0.6402 - auc_1: 0.6996 - val_loss: 0.6799 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6247\n",
      "Epoch 35/1000\n",
      "31/31 [==============================] - 23s 726ms/step - loss: 0.6428 - binary_accuracy: 0.6260 - auc_1: 0.6761 - val_loss: 0.6803 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6215\n",
      "Epoch 36/1000\n",
      "31/31 [==============================] - 23s 722ms/step - loss: 0.6365 - binary_accuracy: 0.6301 - auc_1: 0.6866 - val_loss: 0.6806 - val_binary_accuracy: 0.5333 - val_auc_1: 0.6242\n",
      "Epoch 37/1000\n",
      "31/31 [==============================] - 23s 725ms/step - loss: 0.6364 - binary_accuracy: 0.6362 - auc_1: 0.6829 - val_loss: 0.6806 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6254\n",
      "Epoch 38/1000\n",
      "31/31 [==============================] - 23s 716ms/step - loss: 0.6457 - binary_accuracy: 0.6077 - auc_1: 0.6796 - val_loss: 0.6803 - val_binary_accuracy: 0.5455 - val_auc_1: 0.6253\n",
      "Epoch 39/1000\n",
      "31/31 [==============================] - 23s 726ms/step - loss: 0.6419 - binary_accuracy: 0.6118 - auc_1: 0.6821 - val_loss: 0.6805 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6261\n",
      "Epoch 40/1000\n",
      "31/31 [==============================] - 23s 725ms/step - loss: 0.6412 - binary_accuracy: 0.6179 - auc_1: 0.6750 - val_loss: 0.6811 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6225\n",
      "Epoch 41/1000\n",
      "31/31 [==============================] - 23s 719ms/step - loss: 0.6446 - binary_accuracy: 0.5915 - auc_1: 0.6646 - val_loss: 0.6812 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6245\n",
      "Epoch 42/1000\n",
      "31/31 [==============================] - 23s 717ms/step - loss: 0.6372 - binary_accuracy: 0.6199 - auc_1: 0.6790 - val_loss: 0.6818 - val_binary_accuracy: 0.5455 - val_auc_1: 0.6208\n",
      "Epoch 43/1000\n",
      "31/31 [==============================] - 23s 717ms/step - loss: 0.6313 - binary_accuracy: 0.6423 - auc_1: 0.6996 - val_loss: 0.6816 - val_binary_accuracy: 0.5455 - val_auc_1: 0.6223\n",
      "Epoch 44/1000\n",
      "31/31 [==============================] - 23s 725ms/step - loss: 0.6394 - binary_accuracy: 0.6118 - auc_1: 0.6758 - val_loss: 0.6821 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6219\n",
      "Epoch 45/1000\n",
      "31/31 [==============================] - 23s 728ms/step - loss: 0.6343 - binary_accuracy: 0.6382 - auc_1: 0.6939 - val_loss: 0.6813 - val_binary_accuracy: 0.5455 - val_auc_1: 0.6250\n",
      "Epoch 46/1000\n",
      "31/31 [==============================] - 23s 724ms/step - loss: 0.6417 - binary_accuracy: 0.6016 - auc_1: 0.6716 - val_loss: 0.6815 - val_binary_accuracy: 0.5455 - val_auc_1: 0.6250\n",
      "Epoch 47/1000\n",
      "31/31 [==============================] - 23s 724ms/step - loss: 0.6435 - binary_accuracy: 0.6138 - auc_1: 0.6684 - val_loss: 0.6814 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6236\n",
      "Epoch 48/1000\n",
      "31/31 [==============================] - 23s 721ms/step - loss: 0.6373 - binary_accuracy: 0.6341 - auc_1: 0.6798 - val_loss: 0.6820 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6246\n",
      "Epoch 49/1000\n",
      "31/31 [==============================] - 23s 736ms/step - loss: 0.6228 - binary_accuracy: 0.6484 - auc_1: 0.7101 - val_loss: 0.6821 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6240\n",
      "Epoch 50/1000\n",
      "31/31 [==============================] - 23s 710ms/step - loss: 0.6300 - binary_accuracy: 0.6159 - auc_1: 0.6983 - val_loss: 0.6823 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6240\n",
      "Epoch 51/1000\n",
      "31/31 [==============================] - 23s 733ms/step - loss: 0.6446 - binary_accuracy: 0.6057 - auc_1: 0.6670 - val_loss: 0.6826 - val_binary_accuracy: 0.5394 - val_auc_1: 0.6233\n",
      "phase 2 complete\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=early_stopping, verbose=1)\n",
    "print('phase 1 complete')\n",
    "# %%\n",
    "#unfreeze all layers and train at lower learning rate\n",
    "base_model.trainable = True\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr_2), \n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=[keras.metrics.BinaryAccuracy(), keras.metrics.AUC()],\n",
    ")\n",
    "model.fit(train_ds, epochs=1000, validation_data=val_ds, callbacks=early_stopping, verbose=1)\n",
    "print('phase 2 complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the final model as a .h5 file\n",
    "model.save('models/{}_{}_cutout.h5'.format(model_name, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 492 files belonging to 2 classes.\n",
      "Found 165 files belonging to 2 classes.\n",
      "Found 164 files belonging to 2 classes.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 1s 641ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "#generate predictions for all images in the dataset, including train and val, and save to one csv\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(train_dir, label_mode='binary', seed=0, shuffle=False, image_size=(img_size, img_size), batch_size=batch_size, color_mode='rgb')\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(val_dir, label_mode='binary', seed=0, shuffle=False, image_size=(img_size, img_size), batch_size=batch_size, color_mode='rgb')\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(test_dir, label_mode='binary', seed=0, shuffle=False, image_size=(img_size, img_size), batch_size=1, color_mode='rgb')\n",
    "y_train_pred = np.array([])\n",
    "y_train = np.array([])\n",
    "for images, labels in train_ds:\n",
    "    y_train = np.append(y_train, labels.numpy())\n",
    "    y_train_pred = np.append(y_train_pred, model.predict(images))\n",
    "train_file_paths = train_ds.file_paths\n",
    "\n",
    "y_val_pred = np.array([])\n",
    "y_val = np.array([])\n",
    "for images, labels in val_ds:\n",
    "    y_val = np.append(y_val, labels.numpy())\n",
    "    y_val_pred = np.append(y_val_pred, model.predict(images))\n",
    "val_file_paths = val_ds.file_paths\n",
    "\n",
    "y_test_pred = np.array([])\n",
    "y_test = np.array([])\n",
    "for images, labels in test_ds:\n",
    "    y_test = np.append(y_test, labels.numpy())\n",
    "    y_test_pred = np.append(y_test_pred, model.predict(images))\n",
    "test_file_paths = test_ds.file_paths\n",
    "\n",
    "y_all_pred = np.append(y_train_pred, y_val_pred)\n",
    "y_all_pred = np.append(y_all_pred, y_test_pred)\n",
    "y_all = np.append(y_train, y_val)\n",
    "y_all = np.append(y_all, y_test)\n",
    "file_paths = np.append(train_file_paths, val_file_paths)\n",
    "file_paths = np.append(file_paths, test_file_paths)\n",
    "pred_df = pd.DataFrame({'file_path': file_paths, 'y_true': y_all, 'y_pred': y_all_pred})\n",
    "pred_df.to_csv('../preds/preds_{}_{}_{}_{}_all.csv'.format(model_name, weights, n_layers, n_neurons), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auroc: 0.7069171138938581\n",
      "val auroc: 0.6248157972295904\n"
     ]
    }
   ],
   "source": [
    "auroc_test = roc_auc_score(y_test, y_test_pred)\n",
    "auroc_val = roc_auc_score(y_val, y_val_pred)\n",
    "print(\"test auroc: {}\".format(auroc_test))\n",
    "print(\"val auroc: {}\".format(auroc_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'model': [model_name], 'weights': [weights], 'image_size': [img_size], 'batch_size': [batch_size], 'lr_1': [lr_1], 'lr_2': [lr_2], 'n_layers': [n_layers], 'n_neurons': [n_neurons], 'n_dropout': [n_dropout], 'auroc_val': auroc_val, 'auroc_test': auroc_test})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
